#!/usr/bin/env python
# coding: utf-8

# In[ ]:
import requests
from bs4 import BeautifulSoup
import os
import zipfile
import subprocess
from colorama import Fore, Style, init

# Inicializamos colorama
init(autoreset=True)

# URL del cat√°logo de publicaciones
catalogo_url = 'https://www.valencia.es/cas/estadistica/catalogo-de-publicaciones'
directorio_descargas = '/home/nnebot/PracticasNicoVRAIN/Datos'

def obtener_ultimo_anuario():
    """
    Obtiene el √∫ltimo anuario estad√≠stico disponible en la p√°gina del Ayuntamiento de Val√®ncia.

    Returns:
        tuple: A√±o m√°s reciente (str) y enlace a la p√°gina del anuario (str).
    """
    print(f"{Fore.YELLOW}{Style.BRIGHT}‚ú® Obteniendo el √∫ltimo anuario disponible... ‚ú®\n")
    response = requests.get(catalogo_url)
    soup = BeautifulSoup(response.content, 'html.parser')

    anuario_section = soup.find_all('tr')
    a√±os = []
    anuario_enlaces = {}
    
    for row in anuario_section:
        titulo = row.find('strong', string=lambda x: x and 'Anuario Estad√≠stico' in x)
        if titulo:
            texto_titulo = titulo.string.strip()
            a√±o = ''.join(filter(str.isdigit, texto_titulo))
            if len(a√±o) == 4:
                enlace_td = row.find('td', class_='text-left padding-left-50px')
                if enlace_td:
                    enlace = enlace_td.find('a', href=True)
                    if enlace:
                        anuario_enlaces[a√±o] = enlace['href']
                        a√±os.append(int(a√±o))

    if a√±os:
        ultimo_a√±o = str(max(a√±os))
        return ultimo_a√±o, anuario_enlaces[ultimo_a√±o]

    return None, None

def verificar_y_descargar_anuario(a√±o, enlace_descarga):
    """
    Verifica y descarga el anuario estad√≠stico para el a√±o especificado, lo descomprime y elimina el ZIP.

    Args:
        a√±o (str): A√±o del anuario.
        enlace_descarga (str): Enlace a la p√°gina de descarga del anuario.
    """
    response = requests.get(enlace_descarga)
    soup = BeautifulSoup(response.content, 'html.parser')

    zip_link = None
    for enlace in soup.find_all('a', href=True):
        if enlace['href'].endswith('.zip'):
            zip_link = enlace['href']
            break

    if zip_link:
        print(f"{Fore.CYAN}üîó Enlace de descarga del archivo .zip: {Style.BRIGHT}{zip_link}")
        response = requests.get(zip_link)
        
        nombre_archivo = os.path.basename(zip_link)
        ruta_archivo = os.path.join(directorio_descargas, nombre_archivo)
        
        with open(ruta_archivo, 'wb') as file:
            file.write(response.content)
        
        print(f"{Fore.GREEN}‚úÖ {nombre_archivo} descargado correctamente.\n")
        
        carpeta_anuario = os.path.join(directorio_descargas, f"Anuario{a√±o}")
        os.makedirs(carpeta_anuario, exist_ok=True)

        with zipfile.ZipFile(ruta_archivo, 'r') as zip_ref:
            zip_ref.extractall(carpeta_anuario)
        print(f"{Fore.YELLOW}üìÇ Contenido extra√≠do en: {carpeta_anuario}")
        
        os.remove(ruta_archivo)
        print(f"{Fore.RED}üóëÔ∏è Archivo .zip eliminado: {nombre_archivo}\n")
    else:
        print(f"{Fore.RED}‚ö†Ô∏è No se encontr√≥ un archivo .zip para descargar.\n")

PARSER_SCRIPT = "/home/nnebot/PracticasNicoVRAIN/Parser_LLM/parser_excel2.py"

TABLAS_A_BUSCAR = {
    "facturaci√≥n_electrica{}.csv": "N√∫mero de contratos y facturaci√≥n por c√≥digo postal y sector econ√≥mico",
    "bienes_inmueblesbarrio{}.csv": "Bienes Inmuebles seg√∫n uso por barrio",
    "bienes_inmueblesdistrito{}.csv": "Bienes Inmuebles seg√∫n uso por distrito",
    "facturacion_gas{}.csv": "Abonados y facturaci√≥n de gas natural por mes seg√∫n tipo de instalaci√≥n",
    "parque_vehiculos{}.csv": "Parque de veh√≠culos seg√∫n tipo de veh√≠culo y carburante",
    "renta_mediana{}.csv": "Renta disponible media por declaraci√≥n de residentes en la ciudad por c√≥digo postal",
    "residuos_urbanos{}.csv": "Residuos s√≥lidos urbanos procedentes de Val√®ncia tratados seg√∫n mes",
    "subproductos_residuos{}.csv": "Subproductos obtenidos del tratamiento de residuos s√≥lidos",
    "turismos_titular{}.csv": "Turismos seg√∫n tipo de titular por distrito",
    "zonasverdes_numero{}.csv": "N√∫mero y superficie de las zonas verdes de gesti√≥n municipal",
    "zonasverdes_superficie{}.csv": "Superficie de las zonas verdes urbanas en la ciudad seg√∫n tipo"
}

def ejecutar_parser(directorio_anuario, a√±o):
    """
    Ejecuta un script parser para extraer tablas espec√≠ficas desde los archivos del anuario descomprimido.

    Args:
        directorio_anuario (str): Ruta al directorio donde se extrajo el anuario.
        a√±o (str): A√±o del anuario, usado para nombrar los archivos de salida.
    """
    cache_dir = '/home/nnebot/PracticasNicoVRAIN/Datos/DatosAnuario'
    os.makedirs(cache_dir, exist_ok=True) 

    print(f"\n{Fore.YELLOW}üîç Iniciando b√∫squeda de tablas para el a√±o {a√±o}...\n")
    for nombre_base, texto_a_buscar in TABLAS_A_BUSCAR.items():
        nombre_fichero = nombre_base.format(a√±o) 
        ruta_salida = os.path.join(cache_dir, nombre_fichero)

        print(f"{Fore.CYAN}üîé Buscando '{texto_a_buscar}'")
        comando = [
            "python3",
            PARSER_SCRIPT,
            "--directory", directorio_anuario,
            "--text", texto_a_buscar,
            "--output", ruta_salida,
            "--cache-dir", cache_dir  
        ]
        try:
            subprocess.run(comando, check=True)
            print(f"{Fore.GREEN}‚úÖ Tabla guardada exitosamente en {ruta_salida}\n")
        except subprocess.CalledProcessError as e:
            print(f"{Fore.RED}‚ö†Ô∏è Error ejecutando el parser para {texto_a_buscar}: {e}\n")

def main():
    """
    Funci√≥n principal que coordina la obtenci√≥n del anuario, su descarga y extracci√≥n de tablas.
    """
    a√±o, enlace_descarga = obtener_ultimo_anuario()
    if a√±o and enlace_descarga:
        print(f"{Fore.YELLOW}üìÖ √öltimo anuario encontrado: {a√±o}\n")
        verificar_y_descargar_anuario(a√±o, enlace_descarga)
        directorio_anuario = os.path.join(directorio_descargas, f"Anuario{a√±o}")
        ejecutar_parser(directorio_anuario, a√±o)
    else:
        print(f"{Fore.RED}‚ö†Ô∏è No se pudo obtener el √∫ltimo anuario.\n")

if __name__ == '__main__':
    main()
